{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Caminho dos arquivos CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_csv_path = \"/usr/local/airflow/artifacts/parquets\"\n",
    "user_target_csv_file = \"users_merged_data.parquet\"\n",
    "\n",
    "articles_csv_path = \"/usr/local/airflow/artifacts/parquets\"\n",
    "articles_target_csv_file = \"articles_merged_data.parquet\"\n",
    "\n",
    "artifacts_models_path = \"/usr/local/airflow/artifacts/models\"\n",
    "validacao_file = \"/usr/local/airflow/data/validacao.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Carregando os dados dos usuários, artigos e validacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_users = pd.read_csv(f\"{user_csv_path}/{user_target_csv_file}\")\n",
    "# df_articles = pd.read_csv(f\"{articles_csv_path}/{articles_target_csv_file}\")\n",
    "df_users = pd.read_parquet(f\"{user_csv_path}/{user_target_csv_file}\")\n",
    "df_articles = pd.read_parquet(f\"{articles_csv_path}/{articles_target_csv_file}\")\n",
    "df_validacao = pd.read_csv(validacao_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preenchendo valores ausentes de 'history' com lista vazia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users.fillna({\"history\": \"[]\"}, inplace=True)  # Se history estiver vazio, substitui por lista vazia\n",
    "df_articles.fillna(\"\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_articles[\"issued\"] = pd.to_datetime(df_articles[\"issued\"]).astype(int) // 10**9\n",
    "df_articles[\"modified\"] = pd.to_datetime(df_articles[\"modified\"]).astype(int) // 10**9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_mean(value):\n",
    "    if isinstance(value, str):\n",
    "        values = [float(x.strip()) for x in value.split(\",\") if x.strip().replace('.', '', 1).isdigit()]\n",
    "        return np.mean(values) if values else 0\n",
    "    return value\n",
    "\n",
    "cols_to_convert = [\"numberOfClicksHistory\", \"timeOnPageHistory\", \"scrollPercentageHistory\", \"pageVisitsCountHistory\"]\n",
    "for col in cols_to_convert:\n",
    "    df_users[col] = df_users[col].apply(convert_to_mean)\n",
    "    \n",
    "df_users.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "df_users[[\n",
    "    \"historySize\",\n",
    "    \"numberOfClicksHistory\",\n",
    "    \"timeOnPageHistory\",\n",
    "    \"scrollPercentageHistory\",\n",
    "    \"pageVisitsCountHistory\"\n",
    "]] = \\\n",
    "    scaler.fit_transform(\n",
    "        df_users[\n",
    "            [\n",
    "                \"historySize\",\n",
    "                \"numberOfClicksHistory\",\n",
    "                \"timeOnPageHistory\",\n",
    "                \"scrollPercentageHistory\",\n",
    "                \"pageVisitsCountHistory\"\n",
    "            ]\n",
    "        ]\n",
    "    )\n",
    "df_users.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users[\"history\"] = df_users[\"history\"].apply(lambda x: x.split(\",\") if isinstance(x, str) else [])\n",
    "df_users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "df_users[\"userType\"] = encoder.fit_transform(df_users[\"userType\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_users[\"userHash\"] = df_users[\"userId\"]\n",
    "# df_users[\"userId\"] = df_users[\"userId\"].astype(\"category\").cat.codes\n",
    "df_articles[\"page\"] = df_articles[\"page\"].astype(\"category\").cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Garantir que todos os usuários da validação estejam incluídos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# users_validacao_ids = df_validacao[\"userId\"].unique()\n",
    "# df_users_validacao = df_users[df_users[\"userId\"].isin(users_validacao_ids)]\n",
    "# df_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users_sampled = df_users.sample(n=6000, random_state=42)  # Amostra de 1000 usuários\n",
    "df_articles_sampled = df_articles.sample(n=1000, random_state=42)  # Amostra de 1000 artigos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_data_sampled = []\n",
    "for _, row in df_users_sampled.iterrows():\n",
    "    for article in row['history']:\n",
    "        interaction_data_sampled.append((row['userId'], article))\n",
    "\n",
    "df_interactions = pd.DataFrame(interaction_data_sampled, columns=[\"userId\", \"page\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_interactions_sampled = df_interactions[\n",
    "#     (df_interactions[\"userId\"].isin(df_users_sampled[\"userId\"])) &\n",
    "#     (df_interactions[\"page\"].isin(df_articles_sampled[\"page\"]))\n",
    "# ]\n",
    "\n",
    "# Divisão em treino e validação\n",
    "# df_train, df_validacaoTemp = train_test_split(df_interactions_sampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Garantir que o conjunto de validação contenha apenas usuários que estão no treino\n",
    "# df_validacaoTemp = df_validacaoTemp[df_validacaoTemp[\"userId\"].isin(df_train[\"userId\"])]\n",
    "\n",
    "# # Exibir tamanhos dos conjuntos\n",
    "# print(f\"Tamanho do conjunto de treino: {df_train.shape[0]}\")\n",
    "# print(f\"Tamanho do conjunto de validação: {df_validacaoTemp.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users_sampled.to_parquet(\"/usr/local/airflow/artifacts/parquets/usuarios_preprocessados.parquet\", index=False)\n",
    "df_articles_sampled.to_parquet(\"/usr/local/airflow/artifacts/parquets/artigos_preprocessados.parquet\", index=False)\n",
    "df_interactions.to_parquet(\"/usr/local/airflow/artifacts/parquets/interactions.parquet\", index=False)\n",
    "\n",
    "print(\"✅ Pré-processamento concluído e salvo em Parquet!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_matrix = df_interactions.pivot_table(index='userId', columns='page', aggfunc='size', fill_value=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim = cosine_similarity(interaction_matrix)\n",
    "cos_sim_df = pd.DataFrame(cos_sim, index=interaction_matrix.index, columns=interaction_matrix.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Matriz de similaridade entre usuários:\")\n",
    "print(cos_sim_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### K Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "df_users_sampled['cluster'] = kmeans.fit_predict(df_users_sampled[['numberOfClicksHistory', 'timeOnPageHistory']])\n",
    "\n",
    "# Exibindo clusters dos usuários\n",
    "print(\"Clusters dos usuários:\")\n",
    "print(df_users_sampled[['userId', 'cluster']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Função para calcular a precisão das recomendações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_recommendations(recommended_articles, history):\n",
    "    # Verifica se history é um array NumPy e converte para lista\n",
    "    if isinstance(history, np.ndarray):\n",
    "        history = history.tolist()  # Converte array NumPy para lista normal\n",
    "    \n",
    "    # Verifica se history é uma string concatenada em vez de uma lista real\n",
    "    if isinstance(history, str):\n",
    "        history = history.strip(\"[]\").replace(\"'\", \"\").split()\n",
    "    \n",
    "    relevant_articles = [article.strip() for article in history]\n",
    "    correct_recommendations = len(set(recommended_articles).intersection(set(relevant_articles)))\n",
    "    total_recommendations = len(recommended_articles)\n",
    "    return correct_recommendations, total_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users_sampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cos_sim_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# teste = users.loc['956bbe18790201499004c41bf9df52c583a9020fa21cbd2e4b117f9391b130f7']\n",
    "# teste\n",
    "# df_validacao.shape\n",
    "users_in_sim_matrix = df_validacao['userId'].isin(cos_sim_df.index).sum()\n",
    "users_in_sim_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Recomendações para usuários de validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_recommendations = 0\n",
    "total_recommendations = 0\n",
    "\n",
    "for _, row in df_validacao.iterrows():\n",
    "    user_id = row['userId']\n",
    "    # print(user_id)\n",
    "    # Verificar se o user_id está presente no cos_sim_df (índice)\n",
    "    if user_id not in cos_sim_df.index:\n",
    "        # print(f\"❌ O userId {user_id} não está presente na matriz de similaridade.\")\n",
    "        continue  # Pula o usuário se não estiver no cos_sim_df\n",
    "\n",
    "    # Usuários similares\n",
    "    user_similarity = cos_sim_df.loc[user_id]\n",
    "    # print(user_similarity)\n",
    "    similar_users = user_similarity.sort_values(ascending=False).index[1:4]\n",
    "\n",
    "    # Artigos recomendados\n",
    "    recommended_articles = []\n",
    "    for similar_user in similar_users:\n",
    "        similar_user_articles = df_interactions[df_interactions['userId'] == similar_user]['page']\n",
    "        recommended_articles.extend(similar_user_articles)\n",
    "\n",
    "    # Removendo duplicatas\n",
    "    recommended_articles = list(set(recommended_articles))\n",
    "\n",
    "    # Avaliar precisão das recomendações\n",
    "    correct, total = evaluate_recommendations(recommended_articles, row['history'])\n",
    "    correct_recommendations += correct\n",
    "    total_recommendations += total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculando a precisão das recomendações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"correct_recommendations: {correct_recommendations}\")\n",
    "print(f\"total_recommendations: {total_recommendations}\")\n",
    "precision = correct_recommendations / total_recommendations if total_recommendations > 0 else 0\n",
    "print(f\"✅ Precisão das recomendações: {precision:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recomendações para um usuário logado\n",
    "user_id = df_users_sampled['userId'].iloc[0]  # Exemplo de usuário logado (pode ser qualquer userId)\n",
    "user_similarity = cos_sim_df[user_id]\n",
    "similar_users = user_similarity.sort_values(ascending=False).index[1:4]\n",
    "print(f\"Usuários mais similares ao usuário {user_id}:\")\n",
    "print(similar_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sugestões de artigos baseadas em similaridade (para o usuário logado)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommended_articles = []\n",
    "for similar_user in similar_users:\n",
    "    similar_user_articles = df_interactions[df_interactions['userId'] == similar_user]['page']\n",
    "    recommended_articles.extend(similar_user_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibindo os artigos recomendados\n",
    "recommended_articles = list(set(recommended_articles))  # Removendo duplicatas\n",
    "recommended_articles = [article.strip() for article in recommended_articles]  # Removendo espaços extras\n",
    "print(\"Artigos recomendados:\")\n",
    "print(recommended_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recomendações para usuários não logados: artigos populares\n",
    "popular_articles = df_interactions.groupby('page').size().reset_index(name='popularity')\n",
    "popular_articles = popular_articles.sort_values('popularity', ascending=False)\n",
    "print(\"Artigos mais populares:\")\n",
    "print(popular_articles.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(kmeans, f\"{artifacts_models_path}/kmeans_model.pkl\")\n",
    "\n",
    "# Save cosine similarity matrix\n",
    "with open(f\"{artifacts_models_path}/cos_sim_matrix.pkl\", \"wb\") as f:\n",
    "    pickle.dump(cos_sim_df, f)\n",
    "\n",
    "# Save user and article DataFrames for later use\n",
    "df_users_sampled.to_pickle(f\"{artifacts_models_path}/usuarios_preprocessados.pkl\")\n",
    "df_articles_sampled.to_pickle(f\"{artifacts_models_path}/artigos_preprocessados.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
